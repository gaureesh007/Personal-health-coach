# Personal-health-coach
making the repo for the gen ai challenge 2
MedReduce AI
Cost-Aware RAG-Based Health Monitoring & Recommendation System
ğŸ“Œ Overview

MedReduce AI is a Retrieval-Augmented Generation (RAG) based health monitoring agent designed to:

Compress longitudinal medical history

Integrate real-time wellness data

Provide personalized health recommendations

Minimize LLM token usage and inference cost

Traditional healthcare AI systems scale poorly because medical history grows indefinitely. Sending full patient history to large language models becomes computationally expensive and inefficient.

This system introduces:

Hierarchical medical memory

Severity-aware retrieval

Delta-based context prompting

Context compression engine

Cost-aware inference strategy

The result is a clinically aware, scalable, and affordable AI health agent.

ğŸ¯ Problem Statement

Medical data is longitudinal and accumulative.

Let:

H(t) = Patient history size over time

C = LLM context window

T = Token cost per request

As time increases:

H(t) >> C
Cost â†’ Linear growth


Traditional RAG:

Retrieves redundant logs

Repeats historical details

Increases token usage

Raises inference cost

We solve this using adaptive medical memory compression and selective retrieval.

ğŸ— System Architecture
User
  â†“
API Gateway
  â†“
Data Ingestion Service
  â†“
Embedding Service
  â†“
Vector Store (FAISS / Pinecone)
  â†“
Retrieval Orchestrator
  â†“
Context Compression Engine
  â†“
Recommendation Engine (LLM + Rule Engine)
  â†“
Personalized Output

ğŸ§© Core Components
1ï¸âƒ£ Data Ingestion Layer

Handles:

Medical history (EHR, PDFs, doctor notes)

Lab reports

Wearable device data

Wellness logs

Processing Steps

OCR (if needed)

Clinical Named Entity Recognition

Structured JSON conversion

Semantic chunking

Embedding generation

2ï¸âƒ£ Hierarchical Medical Memory

Instead of storing all history equally, we implement tiered memory:

Tier	Data Type	Detail Level
Tier 1	Chronic / Active conditions	Full detail
Tier 2	Recent 6 months	Medium detail
Tier 3	Older history	Summarized

This prevents token explosion while preserving critical context.

3ï¸âƒ£ Retrieval Pipeline
Multi-Stage Retrieval Strategy

Dense vector retrieval (Top-K)

Metadata filtering (patient_id, severity)

Severity-based re-ranking

Recency-based decay scoring

Final Score Formula
FinalScore =
0.5 * similarity_score +
0.3 * severity_weight +
0.2 * recency_weight


Where:

recency_weight = e^(-Î» * age_in_days)


This ensures recent and severe medical events are prioritized.

4ï¸âƒ£ Context Compression Engine
Why It Matters

Medical logs often contain repeated measurements:

Instead of:

BP: 140/90
BP: 142/92
BP: 145/95

We compress into:

Sustained upward blood pressure trend over 3 weeks.

Compression Strategies

Time-series aggregation

Trend detection

Condition grouping

Delta summarization

Redundant chunk elimination

Compression Ratio Target
> 60% reduction in tokens

5ï¸âƒ£ Recommendation Engine

Hybrid architecture:

A. Rule-Based Layer

Handles deterministic medical thresholds.

Example:

IF systolic_BP > 140
THEN risk = High

B. LLM Reasoning Layer

Receives:

Compressed medical summary

Recent anomalies

Baseline profile

Outputs:

Risk level

Lifestyle adjustments

Alert recommendations

Confidence score

ğŸ’° Cost Optimization Strategy

Healthcare AI becomes expensive due to token usage.

We minimize cost using:

Smaller embedding models

Tiered summarization

Delta-based prompting

Query caching

Token budget control

Selective context injection

Cost Formula
TotalCost =
( InputTokens + OutputTokens ) Ã— LLM_Cost
+ EmbeddingCost


Goal: Minimize InputTokens without sacrificing accuracy.

ğŸ“Š Data Model
Patients Table

patient_id

age

gender

baseline_summary

Medical Events

event_id

condition

severity

timestamp

structured_data (JSON)

Wellness Logs

heart_rate

sleep_hours

stress_index

timestamp

ğŸ” Security & Privacy

AES-256 encryption (at rest)

TLS encryption (in transit)

JWT-based authentication

Role-based access control

De-identification of patient records

Optional local vector storage

Designed to support:

HIPAA compliance

GDPR alignment

ğŸ“ˆ Evaluation Metrics
Technical Metrics

Retrieval Precision @ K

Compression Ratio

Latency (< 2 seconds)

Cost per query (< $0.01)

Token usage per request

Clinical Metrics

Risk classification accuracy

False positive rate

Doctor validation score

User adherence improvement

ğŸ›  Tech Stack
Backend

Python

FastAPI

LangChain / LlamaIndex

ML / AI

Sentence Transformers

FAISS / Pinecone

OpenAI / Claude / Local LLM

Database

PostgreSQL

Vector Database

Frontend

React / Next.js

Deployment

Docker

AWS / GCP

ğŸš€ API Example
POST /recommend

Request

{
  "patient_id": "uuid",
  "query": "Assess my cardiovascular health."
}


Response

{
  "risk_level": "Medium",
  "summary": "Recent sustained BP elevation with low sleep average.",
  "recommendations": [
    "Reduce sodium intake",
    "Improve sleep hygiene",
    "Consult physician if BP remains elevated for 2 weeks"
  ],
  "confidence_score": 0.91
}

ğŸ§ª Research Contributions

This system introduces:

Cost-aware RAG in healthcare

Hierarchical medical memory

Severity-weighted retrieval

Delta-context prompting

Adaptive compression strategy

Potential publication domain:

AI in Healthcare

Efficient LLM Systems

Context Compression Research

ğŸ”® Future Enhancements

Multimodal ECG embeddings

Federated patient learning

On-device summarization

Reinforcement-based adaptive compression

AI health twin modeling

âš  Disclaimer

This system provides AI-assisted health insights and does not replace professional medical advice. Clinical decisions must be validated by licensed healthcare professionals.

ğŸ“Œ Why This Project Is Different

Most healthcare chatbots:

Dump full context into LLM

Ignore cost scaling

Lack structured memory

MedReduce AI:

Treats medical history as evolving memory

Compresses intelligently

Optimizes token economy

Maintains personalization
